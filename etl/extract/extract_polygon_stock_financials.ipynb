{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "429f26a2-23e5-44d4-9f5a-1f1cd8130856",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pipeline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a205808e-b92b-495d-a7b0-459968871b2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.widgets.text(\"input_load_date\", \"YYYY-MM-DD\", \"Input Load Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db4385b8-a95a-456c-ac0b-c719f92b6e4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./aws_secret_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "776764db-2d5f-4894-aa6b-a2daddedfa3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import csv\n",
    "import datetime as dt\n",
    "import os\n",
    "from ast import literal_eval\n",
    "\n",
    "# Third-party library imports\n",
    "import pyarrow as pa\n",
    "import requests as r\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql.functions import cast, col, current_timestamp\n",
    "from pyspark.sql.types import (\n",
    "    DateType,\n",
    "    DoubleType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9da76bd9-b61a-4461-9df3-1821c8254820",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "catalog_name = os.getenv('DATABRICKS_CATALOG_NAME')\n",
    "schema_name = os.getenv('DATABRICKS_SCHEMA_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33249bba-34ec-4c18-ba44-1fe9a6233912",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stock_financials_schema = StructType([\n",
    "    StructField(\"ticker_symbol\", StringType(), True),\n",
    "    StructField(\"start_date\", StringType(), True),\n",
    "    StructField(\"end_date\", StringType(), True),\n",
    "    StructField(\"filing_date\", StringType(), True),\n",
    "    StructField(\"fiscal_period\", StringType(), True),\n",
    "    StructField(\"fiscal_year\", StringType(), True),\n",
    "    StructField(\"diluted_earnings_per_share\", StringType(), True),\n",
    "    StructField(\"net_income_loss\", StringType(), True),\n",
    "    StructField(\"equity\", StringType(), True),\n",
    "    StructField(\"long_term_debt\", StringType(), True),\n",
    "    StructField(\"diluted_average_shares\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c56142b9-3be6-4f79-977f-3da8a074f420",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load Stock Price Data for S&P500 Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23a30cef-4b80-416d-8045-3c157eeed6b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SP500_tickers = (spark.read.table(f'{catalog_name}.{schema_name}.kdayno_bronze_SP500_companies')\n",
    "                  .select('ticker_symbol')\n",
    "                )\n",
    "\n",
    "SP500_tickers_list = [row['ticker_symbol'] for row in SP500_tickers.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e1bbab9-30d8-4d4e-b4eb-0e95ef209f62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "polygon_api_key = literal_eval(get_secret(\"POLYGON_CREDENTIALS\"))['AWS_SECRET_ACCESS_KEY']\n",
    "stock_financials = {'ticker_symbol':[], 'start_date':[], 'end_date':[], 'filing_date':[], 'fiscal_period':[], 'fiscal_year':[], 'diluted_earnings_per_share':[], 'net_income_loss':[], 'equity':[], 'long_term_debt':[], 'diluted_average_shares':[]}\n",
    "\n",
    "for ticker_symbol in SP500_tickers_list:\n",
    "    polygon_url = f\"https://api.polygon.io/vX/reference/financials?ticker={ticker_symbol}&timeframe=annual&limit=10&apiKey=\"\n",
    "\n",
    "    data = r.get(f'{polygon_url}{polygon_api_key}').json()\n",
    "    print(f'Getting financial data for ticker: {ticker_symbol} ...')\n",
    "\n",
    "    if data['results']:\n",
    "        stock_financials['ticker_symbol'].append(ticker_symbol)\n",
    "        stock_financials['start_date'].append(data['results'][0].get('start_date'))\n",
    "        stock_financials['end_date'].append(data['results'][0].get('end_date'))\n",
    "        stock_financials['filing_date'].append(data['results'][0].get('filing_date'))\n",
    "        stock_financials['fiscal_period'].append(data['results'][0].get('fiscal_period'))\n",
    "        stock_financials['fiscal_year'].append(data['results'][0].get('fiscal_year'))\n",
    "        stock_financials['diluted_earnings_per_share'].append(data['results'][0]['financials']['income_statement'].get('diluted_earnings_per_share',{}).get('value', 0))\n",
    "        stock_financials['net_income_loss'].append(data['results'][0]['financials']['income_statement'].get('net_income_loss',{}).get('value', 0))\n",
    "        stock_financials['equity'].append(data['results'][0]['financials']['balance_sheet'].get('equity',{}).get('value', 0))\n",
    "        stock_financials['long_term_debt'].append(data['results'][0]['financials']['balance_sheet'].get('long_term_debt',{}).get('value', 0))\n",
    "        stock_financials['diluted_average_shares'].append(data['results'][0]['financials']['income_statement'].get('diluted_average_shares',{}).get('value', 0))\n",
    "\n",
    "    else:\n",
    "        print(f'No financial data found for ticker: {ticker_symbol}.')\n",
    "\n",
    "stock_financials_df = spark.createDataFrame(list(zip(*stock_financials.values())), stock_financials_schema)\n",
    "\n",
    "\n",
    "stock_financials_transformed_df = (stock_financials_df.withColumn('start_date', col('start_date').cast('date'))\n",
    "                                                      .withColumn('end_date', col('end_date').cast('date'))\n",
    "                                                      .withColumn('filing_date', col('filing_date').cast('date'))\n",
    "                                                      .withColumn('diluted_earnings_per_share', col('diluted_earnings_per_share').cast('double'))\n",
    "                                                      .withColumn('net_income_loss', col('net_income_loss').cast('double'))\n",
    "                                                      .withColumn('equity', col('equity').cast('double'))\n",
    "                                                      .withColumn('long_term_debt', col('long_term_debt').cast('double'))\n",
    "                                                      .withColumn('diluted_average_shares', col('diluted_average_shares').cast('double'))\n",
    "                                                      .withColumn('load_date_ts', current_timestamp()))\n",
    "\n",
    "\n",
    "(stock_financials_transformed_df.write.format(\"delta\")\n",
    "                        .mode(\"overwrite\")\n",
    "                        .saveAsTable(f'{catalog_name}.{schema_name}.kdayno_bronze_SP500_stock_financials'))\n",
    "        \n",
    "print(f'Run successful.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "574273b8-a6c2-4018-8878-446950283a02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6368848666127853,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "extract_polygon_stock_financials",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
